{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiska\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\jiska\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\jiska\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr\n",
    "from utils.helper import Helper\n",
    "helper = Helper()\n",
    "\n",
    "# Load the users and the recommendations from traditional aggregation methods\n",
    "user_profiles = helper.load_data('results/user_profiles.pkl')\n",
    "groups_exp_1 = helper.load_data('results/groups_exp_1.pkl')\n",
    "groups_exp_2 = helper.load_data('results/groups_exp_2.pkl')\n",
    "recommendations_exp_1 = helper.load_data('results/recommendations_exp_1.pkl')\n",
    "recommendations_exp_2 = helper.load_data('results/recommendations_exp_2.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the user profiles containing tag ratings of each group\n",
    "def get_groups(groups_exp):\n",
    "    groups = {}\n",
    "    for g, group in enumerate(groups_exp):\n",
    "        members = {}\n",
    "        for user in group:\n",
    "            for id in user.keys():\n",
    "                members[id] = user_profiles[id]\n",
    "        groups[g] = members\n",
    "    return groups\n",
    "\n",
    "# Create matrix of users and tag ratings for computing similarity between users\n",
    "def create_matrix(groups):\n",
    "    result = {}\n",
    "    for group_id, group in groups.items():\n",
    "        # Step 1: Collect all unique strings for the current group\n",
    "        unique_strings = set()\n",
    "        for ratings in group.values():\n",
    "            unique_strings.update(ratings.keys())\n",
    "        \n",
    "        # Convert the set to a list to use as columns in DataFrame\n",
    "        unique_strings = list(unique_strings)\n",
    "\n",
    "        # Step 2: Create mapping of user ids to row indices\n",
    "        users = list(group.keys())\n",
    "        user_index = {user: idx for idx, user in enumerate(users)}\n",
    "\n",
    "        # Step 3: Initialize an empty matrix\n",
    "        num_users = len(users)\n",
    "        num_strings = len(unique_strings)\n",
    "        matrix = np.full((num_users, num_strings), np.nan)  # Using np.nan for missing ratings\n",
    "\n",
    "        # Step 4: Populate the matrix\n",
    "        string_index = {string: idx for idx, string in enumerate(unique_strings)}\n",
    "        for member, ratings in group.items():\n",
    "            for string, rating in ratings.items():\n",
    "                row_idx = user_index[member]\n",
    "                col_idx = string_index[string]\n",
    "                matrix[row_idx, col_idx] = rating\n",
    "\n",
    "        # Convert to pandas DataFrame for better readability\n",
    "        df = pd.DataFrame(matrix, index=users, columns=unique_strings)\n",
    "        \n",
    "        # Store the DataFrame in the result dictionary\n",
    "        result[group_id] = df\n",
    "        \n",
    "    return result\n",
    "\n",
    "# Similarity functions\n",
    "def cosine_similarity(matrix):\n",
    "    num_users = matrix.shape[0]\n",
    "    similarity_matrix = np.zeros((num_users, num_users))\n",
    "\n",
    "    for i in range(num_users):\n",
    "        for j in range(num_users):\n",
    "            if i != j:\n",
    "                similarity_matrix[i, j] = 1 - cosine(matrix[i], matrix[j])\n",
    "            else:\n",
    "                similarity_matrix[i, j] = 1.0  # Similarity with itself is 1\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "def pearson_similarity(matrix):\n",
    "    num_users = matrix.shape[0]\n",
    "    similarity_matrix = np.zeros((num_users, num_users))\n",
    "\n",
    "    for i in range(num_users):\n",
    "        for j in range(num_users):\n",
    "            if i != j:\n",
    "                valid_indices = ~np.isnan(matrix[i]) & ~np.isnan(matrix[j])\n",
    "                if np.sum(valid_indices) > 0:\n",
    "                    similarity_matrix[i, j], _ = pearsonr(matrix[i, valid_indices], matrix[j, valid_indices])\n",
    "                else:\n",
    "                    similarity_matrix[i, j] = 0  # If no valid ratings overlap, similarity is 0\n",
    "            else:\n",
    "                similarity_matrix[i, j] = 1.0  # Similarity with itself is 1\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "def compute_group_similarities(groups_matrix):\n",
    "    similarity_results = {}\n",
    "\n",
    "    for group_id, df in groups_matrix.items():\n",
    "        matrix = df.to_numpy()\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        cosine_sim = cosine_similarity(matrix)\n",
    "        cosine_sim_df = pd.DataFrame(cosine_sim, index=df.index, columns=df.index)\n",
    "\n",
    "        # Compute pearson similarity\n",
    "        pearson_sim = pearson_similarity(matrix)\n",
    "        pearson_sim_df = pd.DataFrame(pearson_sim, index=df.index, columns=df.index)\n",
    "\n",
    "        similarity_results[group_id] = {\n",
    "            'cosine_similarity': cosine_sim_df,\n",
    "            'pearson_similarity': pearson_sim_df\n",
    "        }\n",
    "\n",
    "    return similarity_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = get_groups(groups_exp_1)\n",
    "groups_matrix = create_matrix(groups)\n",
    "group_similarities = compute_group_similarities(groups_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0: {'cosine_similarity':         11176   52448   64625   37036   288146\n  11176      1.0     1.0     1.0     1.0     1.0\n  52448      1.0     1.0     1.0     1.0     1.0\n  64625      1.0     1.0     1.0     1.0     1.0\n  37036      1.0     1.0     1.0     1.0     1.0\n  288146     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           11176     52448     64625     37036     288146\n  11176   1.000000  0.058479  0.068283  0.085263 -0.059640\n  52448   0.058479  1.000000 -0.035605  0.028293 -0.066133\n  64625   0.068283 -0.035605  1.000000  0.000721  0.028975\n  37036   0.085263  0.028293  0.000721  1.000000 -0.007267\n  288146 -0.059640 -0.066133  0.028975 -0.007267  1.000000},\n 1: {'cosine_similarity':         2310    962690  283390  129201  779699\n  2310       1.0     1.0     1.0     1.0     1.0\n  962690     1.0     1.0     1.0     1.0     1.0\n  283390     1.0     1.0     1.0     1.0     1.0\n  129201     1.0     1.0     1.0     1.0     1.0\n  779699     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           2310      962690    283390    129201    779699\n  2310    1.000000 -0.040254  0.024149  0.022783 -0.071443\n  962690 -0.040254  1.000000  0.097615  0.015932  0.072568\n  283390  0.024149  0.097615  1.000000 -0.008895  0.071302\n  129201  0.022783  0.015932 -0.008895  1.000000 -0.008146\n  779699 -0.071443  0.072568  0.071302 -0.008146  1.000000},\n 2: {'cosine_similarity':         143721  32058   124416  24386   80998 \n  143721     1.0     1.0     1.0     1.0     1.0\n  32058      1.0     1.0     1.0     1.0     1.0\n  124416     1.0     1.0     1.0     1.0     1.0\n  24386      1.0     1.0     1.0     1.0     1.0\n  80998      1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           143721    32058     124416    24386     80998 \n  143721  1.000000 -0.010903 -0.046894  0.056039 -0.016727\n  32058  -0.010903  1.000000  0.113522 -0.017767 -0.012793\n  124416 -0.046894  0.113522  1.000000  0.025278  0.050114\n  24386   0.056039 -0.017767  0.025278  1.000000  0.013472\n  80998  -0.016727 -0.012793  0.050114  0.013472  1.000000},\n 3: {'cosine_similarity':          57222    199792   1052873  594139   593513 \n  57222        1.0      1.0      1.0      1.0      1.0\n  199792       1.0      1.0      1.0      1.0      1.0\n  1052873      1.0      1.0      1.0      1.0      1.0\n  594139       1.0      1.0      1.0      1.0      1.0\n  593513       1.0      1.0      1.0      1.0      1.0,\n  'pearson_similarity':           57222     199792    1052873   594139    593513 \n  57222    1.000000  0.046099 -0.018738  0.051305  0.038458\n  199792   0.046099  1.000000 -0.079373  0.097153  0.075211\n  1052873 -0.018738 -0.079373  1.000000 -0.074756 -0.018741\n  594139   0.051305  0.097153 -0.074756  1.000000  0.053397\n  593513   0.038458  0.075211 -0.018741  0.053397  1.000000},\n 4: {'cosine_similarity':         93006   64203   93446   427184  207176\n  93006      1.0     1.0     1.0     1.0     1.0\n  64203      1.0     1.0     1.0     1.0     1.0\n  93446      1.0     1.0     1.0     1.0     1.0\n  427184     1.0     1.0     1.0     1.0     1.0\n  207176     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           93006     64203     93446     427184    207176\n  93006   1.000000 -0.006322 -0.027619  0.027365 -0.000706\n  64203  -0.006322  1.000000 -0.023237 -0.007145  0.044370\n  93446  -0.027619 -0.023237  1.000000 -0.067411 -0.043611\n  427184  0.027365 -0.007145 -0.067411  1.000000 -0.014612\n  207176 -0.000706  0.044370 -0.043611 -0.014612  1.000000},\n 5: {'cosine_similarity':         114027  398275  172369  463202  36944 \n  114027     1.0     1.0     1.0     1.0     1.0\n  398275     1.0     1.0     1.0     1.0     1.0\n  172369     1.0     1.0     1.0     1.0     1.0\n  463202     1.0     1.0     1.0     1.0     1.0\n  36944      1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           114027    398275    172369    463202    36944 \n  114027  1.000000  0.013542 -0.075734 -0.001836  0.040336\n  398275  0.013542  1.000000  0.120239  0.019356  0.149691\n  172369 -0.075734  0.120239  1.000000  0.013857 -0.034175\n  463202 -0.001836  0.019356  0.013857  1.000000  0.073957\n  36944   0.040336  0.149691 -0.034175  0.073957  1.000000},\n 6: {'cosine_similarity':         246482  284897  58038   621626  407007\n  246482     1.0     1.0     1.0     1.0     1.0\n  284897     1.0     1.0     1.0     1.0     1.0\n  58038      1.0     1.0     1.0     1.0     1.0\n  621626     1.0     1.0     1.0     1.0     1.0\n  407007     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           246482    284897    58038     621626    407007\n  246482  1.000000 -0.033784  0.024471 -0.026279 -0.061950\n  284897 -0.033784  1.000000  0.019982 -0.007803 -0.026954\n  58038   0.024471  0.019982  1.000000  0.117190 -0.089040\n  621626 -0.026279 -0.007803  0.117190  1.000000  0.055026\n  407007 -0.061950 -0.026954 -0.089040  0.055026  1.000000},\n 7: {'cosine_similarity':         283251  35526   383853  340141  126104\n  283251     1.0     1.0     1.0     1.0     1.0\n  35526      1.0     1.0     1.0     1.0     1.0\n  383853     1.0     1.0     1.0     1.0     1.0\n  340141     1.0     1.0     1.0     1.0     1.0\n  126104     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           283251    35526     383853    340141    126104\n  283251  1.000000 -0.018199 -0.020408  0.050037  0.004076\n  35526  -0.018199  1.000000 -0.011172  0.041100  0.110022\n  383853 -0.020408 -0.011172  1.000000  0.042086  0.033865\n  340141  0.050037  0.041100  0.042086  1.000000  0.038167\n  126104  0.004076  0.110022  0.033865  0.038167  1.000000},\n 8: {'cosine_similarity':         840768  552613  481092  222055  86512 \n  840768     1.0     1.0     1.0     1.0     1.0\n  552613     1.0     1.0     1.0     1.0     1.0\n  481092     1.0     1.0     1.0     1.0     1.0\n  222055     1.0     1.0     1.0     1.0     1.0\n  86512      1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           840768    552613    481092    222055    86512 \n  840768  1.000000  0.060792 -0.107575 -0.092469  0.031724\n  552613  0.060792  1.000000 -0.021013 -0.114533  0.064211\n  481092 -0.107575 -0.021013  1.000000 -0.006675 -0.036289\n  222055 -0.092469 -0.114533 -0.006675  1.000000 -0.006597\n  86512   0.031724  0.064211 -0.036289 -0.006597  1.000000},\n 9: {'cosine_similarity':         199020  32772   546010  35635   146284\n  199020     1.0     1.0     1.0     1.0     1.0\n  32772      1.0     1.0     1.0     1.0     1.0\n  546010     1.0     1.0     1.0     1.0     1.0\n  35635      1.0     1.0     1.0     1.0     1.0\n  146284     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           199020    32772     546010    35635     146284\n  199020  1.000000 -0.009386 -0.081856  0.035663 -0.007250\n  32772  -0.009386  1.000000  0.162283  0.061019  0.012971\n  546010 -0.081856  0.162283  1.000000  0.021681 -0.019774\n  35635   0.035663  0.061019  0.021681  1.000000 -0.008142\n  146284 -0.007250  0.012971 -0.019774 -0.008142  1.000000},\n 10: {'cosine_similarity':          1365025  280166   65197    465829   350750 \n  1365025      1.0      1.0      1.0      1.0      1.0\n  280166       1.0      1.0      1.0      1.0      1.0\n  65197        1.0      1.0      1.0      1.0      1.0\n  465829       1.0      1.0      1.0      1.0      1.0\n  350750       1.0      1.0      1.0      1.0      1.0,\n  'pearson_similarity':           1365025   280166    65197     465829    350750 \n  1365025  1.000000  0.088056 -0.049953 -0.010860 -0.015718\n  280166   0.088056  1.000000 -0.053076 -0.037348 -0.082730\n  65197   -0.049953 -0.053076  1.000000  0.071094 -0.028483\n  465829  -0.010860 -0.037348  0.071094  1.000000 -0.079509\n  350750  -0.015718 -0.082730 -0.028483 -0.079509  1.000000},\n 11: {'cosine_similarity':          60989    37868    36128    2123645  126435 \n  60989        1.0      1.0      1.0      1.0      1.0\n  37868        1.0      1.0      1.0      1.0      1.0\n  36128        1.0      1.0      1.0      1.0      1.0\n  2123645      1.0      1.0      1.0      1.0      1.0\n  126435       1.0      1.0      1.0      1.0      1.0,\n  'pearson_similarity':           60989     37868     36128     2123645   126435 \n  60989    1.000000 -0.073968  0.089031  0.038465 -0.041061\n  37868   -0.073968  1.000000  0.081475  0.227733 -0.017210\n  36128    0.089031  0.081475  1.000000  0.098768 -0.037485\n  2123645  0.038465  0.227733  0.098768  1.000000 -0.039478\n  126435  -0.041061 -0.017210 -0.037485 -0.039478  1.000000},\n 12: {'cosine_similarity':         218535  68884   25792   73836   237123\n  218535     1.0     1.0     1.0     1.0     1.0\n  68884      1.0     1.0     1.0     1.0     1.0\n  25792      1.0     1.0     1.0     1.0     1.0\n  73836      1.0     1.0     1.0     1.0     1.0\n  237123     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           218535    68884     25792     73836     237123\n  218535  1.000000 -0.050127 -0.007031  0.031629 -0.066632\n  68884  -0.050127  1.000000  0.034739  0.118577 -0.020649\n  25792  -0.007031  0.034739  1.000000 -0.046058 -0.045258\n  73836   0.031629  0.118577 -0.046058  1.000000  0.014461\n  237123 -0.066632 -0.020649 -0.045258  0.014461  1.000000},\n 13: {'cosine_similarity':         953275  27678   15521   174991  173314\n  953275     1.0     1.0     1.0     1.0     1.0\n  27678      1.0     1.0     1.0     1.0     1.0\n  15521      1.0     1.0     1.0     1.0     1.0\n  174991     1.0     1.0     1.0     1.0     1.0\n  173314     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           953275    27678     15521     174991    173314\n  953275  1.000000 -0.014730 -0.040813 -0.062059  0.059096\n  27678  -0.014730  1.000000  0.082877  0.041086 -0.044201\n  15521  -0.040813  0.082877  1.000000  0.108135  0.101823\n  174991 -0.062059  0.041086  0.108135  1.000000  0.028601\n  173314  0.059096 -0.044201  0.101823  0.028601  1.000000},\n 14: {'cosine_similarity':         187373  993604  137911  156034  88378 \n  187373     1.0     1.0     1.0     1.0     1.0\n  993604     1.0     1.0     1.0     1.0     1.0\n  137911     1.0     1.0     1.0     1.0     1.0\n  156034     1.0     1.0     1.0     1.0     1.0\n  88378      1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           187373    993604    137911    156034    88378 \n  187373  1.000000 -0.093678 -0.037646  0.037334 -0.004132\n  993604 -0.093678  1.000000 -0.049393  0.003051  0.010372\n  137911 -0.037646 -0.049393  1.000000 -0.129158 -0.107119\n  156034  0.037334  0.003051 -0.129158  1.000000 -0.008323\n  88378  -0.004132  0.010372 -0.107119 -0.008323  1.000000},\n 15: {'cosine_similarity':         296027  402559  590105  177933  60124 \n  296027     1.0     1.0     1.0     1.0     1.0\n  402559     1.0     1.0     1.0     1.0     1.0\n  590105     1.0     1.0     1.0     1.0     1.0\n  177933     1.0     1.0     1.0     1.0     1.0\n  60124      1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           296027    402559    590105    177933    60124 \n  296027  1.000000 -0.031332  0.001272 -0.068779 -0.005999\n  402559 -0.031332  1.000000 -0.020672 -0.033388 -0.070643\n  590105  0.001272 -0.020672  1.000000  0.008721  0.055974\n  177933 -0.068779 -0.033388  0.008721  1.000000  0.080465\n  60124  -0.005999 -0.070643  0.055974  0.080465  1.000000},\n 16: {'cosine_similarity':          311003   470351   1056692  55380    129958 \n  311003       1.0      1.0      1.0      1.0      1.0\n  470351       1.0      1.0      1.0      1.0      1.0\n  1056692      1.0      1.0      1.0      1.0      1.0\n  55380        1.0      1.0      1.0      1.0      1.0\n  129958       1.0      1.0      1.0      1.0      1.0,\n  'pearson_similarity':           311003    470351    1056692   55380     129958 \n  311003   1.000000 -0.083841  0.078136 -0.071899  0.028511\n  470351  -0.083841  1.000000 -0.046401  0.011587  0.073793\n  1056692  0.078136 -0.046401  1.000000  0.002366 -0.019883\n  55380   -0.071899  0.011587  0.002366  1.000000 -0.037165\n  129958   0.028511  0.073793 -0.019883 -0.037165  1.000000},\n 17: {'cosine_similarity':          318262   233583   56463    1925885  2324285\n  318262       1.0      1.0      1.0      1.0      1.0\n  233583       1.0      1.0      1.0      1.0      1.0\n  56463        1.0      1.0      1.0      1.0      1.0\n  1925885      1.0      1.0      1.0      1.0      1.0\n  2324285      1.0      1.0      1.0      1.0      1.0,\n  'pearson_similarity':           318262    233583    56463     1925885   2324285\n  318262   1.000000 -0.050524 -0.007330 -0.074371 -0.068257\n  233583  -0.050524  1.000000 -0.036033 -0.014432 -0.040353\n  56463   -0.007330 -0.036033  1.000000  0.045074 -0.038687\n  1925885 -0.074371 -0.014432  0.045074  1.000000  0.046432\n  2324285 -0.068257 -0.040353 -0.038687  0.046432  1.000000},\n 18: {'cosine_similarity':          51011    678366   135887   1329782  303700 \n  51011        1.0      1.0      1.0      1.0      1.0\n  678366       1.0      1.0      1.0      1.0      1.0\n  135887       1.0      1.0      1.0      1.0      1.0\n  1329782      1.0      1.0      1.0      1.0      1.0\n  303700       1.0      1.0      1.0      1.0      1.0,\n  'pearson_similarity':           51011     678366    135887    1329782   303700 \n  51011    1.000000 -0.084236  0.126735  0.018493 -0.109024\n  678366  -0.084236  1.000000 -0.033183 -0.054445 -0.087344\n  135887   0.126735 -0.033183  1.000000  0.000186  0.000523\n  1329782  0.018493 -0.054445  0.000186  1.000000  0.011428\n  303700  -0.109024 -0.087344  0.000523  0.011428  1.000000},\n 19: {'cosine_similarity':         75497   724516  180898  115758  360437\n  75497      1.0     1.0     1.0     1.0     1.0\n  724516     1.0     1.0     1.0     1.0     1.0\n  180898     1.0     1.0     1.0     1.0     1.0\n  115758     1.0     1.0     1.0     1.0     1.0\n  360437     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           75497     724516    180898    115758    360437\n  75497   1.000000 -0.000470  0.002911  0.079742  0.143861\n  724516 -0.000470  1.000000 -0.093591  0.059013 -0.008604\n  180898  0.002911 -0.093591  1.000000  0.013605  0.000301\n  115758  0.079742  0.059013  0.013605  1.000000  0.022903\n  360437  0.143861 -0.008604  0.000301  0.022903  1.000000},\n 20: {'cosine_similarity':             185446      30534       444132      2000431901  570804    \n  185446             1.0         1.0         1.0         1.0         1.0\n  30534              1.0         1.0         1.0         1.0         1.0\n  444132             1.0         1.0         1.0         1.0         1.0\n  2000431901         1.0         1.0         1.0         1.0         1.0\n  570804             1.0         1.0         1.0         1.0         1.0,\n  'pearson_similarity':             185446      30534       444132      2000431901  570804    \n  185446        1.000000    0.004380    0.114822    0.015107   -0.065710\n  30534         0.004380    1.000000   -0.005163    0.014912   -0.028299\n  444132        0.114822   -0.005163    1.000000   -0.021352    0.157644\n  2000431901    0.015107    0.014912   -0.021352    1.000000    0.007964\n  570804       -0.065710   -0.028299    0.157644    0.007964    1.000000},\n 21: {'cosine_similarity':          192264   1706426  284180   358796   394592 \n  192264       1.0      1.0      1.0      1.0      1.0\n  1706426      1.0      1.0      1.0      1.0      1.0\n  284180       1.0      1.0      1.0      1.0      1.0\n  358796       1.0      1.0      1.0      1.0      1.0\n  394592       1.0      1.0      1.0      1.0      1.0,\n  'pearson_similarity':           192264    1706426   284180    358796    394592 \n  192264   1.000000  0.149165 -0.021928  0.001284  0.003081\n  1706426  0.149165  1.000000  0.030594  0.054246 -0.041208\n  284180  -0.021928  0.030594  1.000000 -0.101639 -0.002195\n  358796   0.001284  0.054246 -0.101639  1.000000 -0.038962\n  394592   0.003081 -0.041208 -0.002195 -0.038962  1.000000},\n 22: {'cosine_similarity':         60260   416985  209441  67103   937635\n  60260      1.0     1.0     1.0     1.0     1.0\n  416985     1.0     1.0     1.0     1.0     1.0\n  209441     1.0     1.0     1.0     1.0     1.0\n  67103      1.0     1.0     1.0     1.0     1.0\n  937635     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           60260     416985    209441    67103     937635\n  60260   1.000000  0.036329 -0.017555  0.086406  0.007395\n  416985  0.036329  1.000000 -0.024160 -0.024000  0.107630\n  209441 -0.017555 -0.024160  1.000000  0.034764  0.187032\n  67103   0.086406 -0.024000  0.034764  1.000000 -0.085656\n  937635  0.007395  0.107630  0.187032 -0.085656  1.000000},\n 23: {'cosine_similarity':         107651  463435  62264   930100  189643\n  107651     1.0     1.0     1.0     1.0     1.0\n  463435     1.0     1.0     1.0     1.0     1.0\n  62264      1.0     1.0     1.0     1.0     1.0\n  930100     1.0     1.0     1.0     1.0     1.0\n  189643     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           107651    463435    62264     930100    189643\n  107651  1.000000  0.022888  0.091486 -0.001741 -0.041452\n  463435  0.022888  1.000000 -0.019156  0.040892  0.004148\n  62264   0.091486 -0.019156  1.000000  0.128734 -0.078463\n  930100 -0.001741  0.040892  0.128734  1.000000  0.034164\n  189643 -0.041452  0.004148 -0.078463  0.034164  1.000000},\n 24: {'cosine_similarity':         264017  673444  14410   281399  92886 \n  264017     1.0     1.0     1.0     1.0     1.0\n  673444     1.0     1.0     1.0     1.0     1.0\n  14410      1.0     1.0     1.0     1.0     1.0\n  281399     1.0     1.0     1.0     1.0     1.0\n  92886      1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           264017    673444    14410     281399    92886 \n  264017  1.000000  0.041336  0.080268 -0.043006 -0.007680\n  673444  0.041336  1.000000 -0.029078 -0.027658  0.021495\n  14410   0.080268 -0.029078  1.000000  0.071831  0.066944\n  281399 -0.043006 -0.027658  0.071831  1.000000 -0.059364\n  92886  -0.007680  0.021495  0.066944 -0.059364  1.000000},\n 25: {'cosine_similarity':         385678  219942  293410  64583   312577\n  385678     1.0     1.0     1.0     1.0     1.0\n  219942     1.0     1.0     1.0     1.0     1.0\n  293410     1.0     1.0     1.0     1.0     1.0\n  64583      1.0     1.0     1.0     1.0     1.0\n  312577     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           385678    219942    293410    64583     312577\n  385678  1.000000  0.045010  0.014625  0.094498 -0.002179\n  219942  0.045010  1.000000 -0.064712 -0.056314  0.095115\n  293410  0.014625 -0.064712  1.000000 -0.038944  0.000741\n  64583   0.094498 -0.056314 -0.038944  1.000000  0.091276\n  312577 -0.002179  0.095115  0.000741  0.091276  1.000000},\n 26: {'cosine_similarity':         146047  344231  227607  209255  38643 \n  146047     1.0     1.0     1.0     1.0     1.0\n  344231     1.0     1.0     1.0     1.0     1.0\n  227607     1.0     1.0     1.0     1.0     1.0\n  209255     1.0     1.0     1.0     1.0     1.0\n  38643      1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           146047    344231    227607    209255    38643 \n  146047  1.000000 -0.015388  0.018977 -0.078318  0.019288\n  344231 -0.015388  1.000000 -0.036444  0.051863  0.003935\n  227607  0.018977 -0.036444  1.000000 -0.047496 -0.054428\n  209255 -0.078318  0.051863 -0.047496  1.000000 -0.039539\n  38643   0.019288  0.003935 -0.054428 -0.039539  1.000000},\n 27: {'cosine_similarity':         28636   64642   125640  60231   35140 \n  28636      1.0     1.0     1.0     1.0     1.0\n  64642      1.0     1.0     1.0     1.0     1.0\n  125640     1.0     1.0     1.0     1.0     1.0\n  60231      1.0     1.0     1.0     1.0     1.0\n  35140      1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           28636     64642     125640    60231     35140 \n  28636   1.000000  0.009174  0.110486 -0.012557  0.015919\n  64642   0.009174  1.000000 -0.031937 -0.044889  0.063513\n  125640  0.110486 -0.031937  1.000000  0.035538  0.007213\n  60231  -0.012557 -0.044889  0.035538  1.000000  0.075700\n  35140   0.015919  0.063513  0.007213  0.075700  1.000000},\n 28: {'cosine_similarity':         160977  165933  13796   439797  209983\n  160977     1.0     1.0     1.0     1.0     1.0\n  165933     1.0     1.0     1.0     1.0     1.0\n  13796      1.0     1.0     1.0     1.0     1.0\n  439797     1.0     1.0     1.0     1.0     1.0\n  209983     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           160977    165933    13796     439797    209983\n  160977  1.000000  0.068290 -0.081164 -0.086997 -0.008926\n  165933  0.068290  1.000000 -0.024356 -0.076247 -0.018231\n  13796  -0.081164 -0.024356  1.000000  0.058701  0.138344\n  439797 -0.086997 -0.076247  0.058701  1.000000 -0.079013\n  209983 -0.008926 -0.018231  0.138344 -0.079013  1.000000},\n 29: {'cosine_similarity':          350938   28649    324621   1366254  171303 \n  350938       1.0      1.0      1.0      1.0      1.0\n  28649        1.0      1.0      1.0      1.0      1.0\n  324621       1.0      1.0      1.0      1.0      1.0\n  1366254      1.0      1.0      1.0      1.0      1.0\n  171303       1.0      1.0      1.0      1.0      1.0,\n  'pearson_similarity':           350938    28649     324621    1366254   171303 \n  350938   1.000000 -0.032798  0.106406 -0.079610  0.131994\n  28649   -0.032798  1.000000  0.099379 -0.070458  0.068836\n  324621   0.106406  0.099379  1.000000 -0.037390 -0.017126\n  1366254 -0.079610 -0.070458 -0.037390  1.000000  0.011933\n  171303   0.131994  0.068836 -0.017126  0.011933  1.000000},\n 30: {'cosine_similarity':         248023  52125   157167  362983  351811\n  248023     1.0     1.0     1.0     1.0     1.0\n  52125      1.0     1.0     1.0     1.0     1.0\n  157167     1.0     1.0     1.0     1.0     1.0\n  362983     1.0     1.0     1.0     1.0     1.0\n  351811     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           248023    52125     157167    362983    351811\n  248023  1.000000  0.058640  0.003203 -0.167609  0.127904\n  52125   0.058640  1.000000  0.082043 -0.028117  0.035798\n  157167  0.003203  0.082043  1.000000  0.026570 -0.001836\n  362983 -0.167609 -0.028117  0.026570  1.000000 -0.064541\n  351811  0.127904  0.035798 -0.001836 -0.064541  1.000000},\n 31: {'cosine_similarity':         302094  74652   361931  22973   480195\n  302094     1.0     1.0     1.0     1.0     1.0\n  74652      1.0     1.0     1.0     1.0     1.0\n  361931     1.0     1.0     1.0     1.0     1.0\n  22973      1.0     1.0     1.0     1.0     1.0\n  480195     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           302094    74652     361931    22973     480195\n  302094  1.000000  0.050322 -0.023091 -0.055458 -0.032829\n  74652   0.050322  1.000000  0.079490 -0.024804 -0.057811\n  361931 -0.023091  0.079490  1.000000 -0.091595  0.069755\n  22973  -0.055458 -0.024804 -0.091595  1.000000 -0.050268\n  480195 -0.032829 -0.057811  0.069755 -0.050268  1.000000},\n 32: {'cosine_similarity':         69838   900992  186855  185285  359220\n  69838      1.0     1.0     1.0     1.0     1.0\n  900992     1.0     1.0     1.0     1.0     1.0\n  186855     1.0     1.0     1.0     1.0     1.0\n  185285     1.0     1.0     1.0     1.0     1.0\n  359220     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           69838     900992    186855    185285    359220\n  69838   1.000000 -0.016611 -0.005929  0.135615  0.118805\n  900992 -0.016611  1.000000  0.029673 -0.001354  0.054123\n  186855 -0.005929  0.029673  1.000000  0.182673  0.014405\n  185285  0.135615 -0.001354  0.182673  1.000000  0.118395\n  359220  0.118805  0.054123  0.014405  0.118395  1.000000},\n 33: {'cosine_similarity':         147027  11297   27643   20480   465056\n  147027     1.0     1.0     1.0     1.0     1.0\n  11297      1.0     1.0     1.0     1.0     1.0\n  27643      1.0     1.0     1.0     1.0     1.0\n  20480      1.0     1.0     1.0     1.0     1.0\n  465056     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           147027    11297     27643     20480     465056\n  147027  1.000000  0.014921 -0.062378  0.025637  0.081681\n  11297   0.014921  1.000000  0.012737  0.024767 -0.006711\n  27643  -0.062378  0.012737  1.000000 -0.051388  0.049765\n  20480   0.025637  0.024767 -0.051388  1.000000  0.000518\n  465056  0.081681 -0.006711  0.049765  0.000518  1.000000},\n 34: {'cosine_similarity':         288218  187281  601528  226867  852554\n  288218     1.0     1.0     1.0     1.0     1.0\n  187281     1.0     1.0     1.0     1.0     1.0\n  601528     1.0     1.0     1.0     1.0     1.0\n  226867     1.0     1.0     1.0     1.0     1.0\n  852554     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           288218    187281    601528    226867    852554\n  288218  1.000000 -0.005307 -0.034901 -0.082533  0.046149\n  187281 -0.005307  1.000000 -0.042616 -0.065683  0.169320\n  601528 -0.034901 -0.042616  1.000000 -0.053643  0.007255\n  226867 -0.082533 -0.065683 -0.053643  1.000000 -0.002121\n  852554  0.046149  0.169320  0.007255 -0.002121  1.000000},\n 35: {'cosine_similarity':          620763   936601   7108     1701315  789516 \n  620763       1.0      1.0      1.0      1.0      1.0\n  936601       1.0      1.0      1.0      1.0      1.0\n  7108         1.0      1.0      1.0      1.0      1.0\n  1701315      1.0      1.0      1.0      1.0      1.0\n  789516       1.0      1.0      1.0      1.0      1.0,\n  'pearson_similarity':           620763    936601    7108      1701315   789516 \n  620763   1.000000 -0.034366 -0.108012  0.036151 -0.013842\n  936601  -0.034366  1.000000  0.008854 -0.063999  0.103237\n  7108    -0.108012  0.008854  1.000000 -0.061823  0.091499\n  1701315  0.036151 -0.063999 -0.061823  1.000000 -0.025718\n  789516  -0.013842  0.103237  0.091499 -0.025718  1.000000},\n 36: {'cosine_similarity':          57042    1105991  195589   229850   193516 \n  57042        1.0      1.0      1.0      1.0      1.0\n  1105991      1.0      1.0      1.0      1.0      1.0\n  195589       1.0      1.0      1.0      1.0      1.0\n  229850       1.0      1.0      1.0      1.0      1.0\n  193516       1.0      1.0      1.0      1.0      1.0,\n  'pearson_similarity':           57042     1105991   195589    229850    193516 \n  57042    1.000000 -0.056163 -0.011101 -0.008581 -0.070358\n  1105991 -0.056163  1.000000  0.189773  0.055037  0.059076\n  195589  -0.011101  0.189773  1.000000 -0.014646 -0.024186\n  229850  -0.008581  0.055037 -0.014646  1.000000 -0.122237\n  193516  -0.070358  0.059076 -0.024186 -0.122237  1.000000},\n 37: {'cosine_similarity':         68526   663997  381180  269521  341170\n  68526      1.0     1.0     1.0     1.0     1.0\n  663997     1.0     1.0     1.0     1.0     1.0\n  381180     1.0     1.0     1.0     1.0     1.0\n  269521     1.0     1.0     1.0     1.0     1.0\n  341170     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           68526     663997    381180    269521    341170\n  68526   1.000000 -0.084071  0.005130 -0.046867 -0.036925\n  663997 -0.084071  1.000000  0.043773  0.024532 -0.033149\n  381180  0.005130  0.043773  1.000000  0.076376 -0.080656\n  269521 -0.046867  0.024532  0.076376  1.000000  0.038452\n  341170 -0.036925 -0.033149 -0.080656  0.038452  1.000000},\n 38: {'cosine_similarity':         131021  64667   6651    706608  232669\n  131021     1.0     1.0     1.0     1.0     1.0\n  64667      1.0     1.0     1.0     1.0     1.0\n  6651       1.0     1.0     1.0     1.0     1.0\n  706608     1.0     1.0     1.0     1.0     1.0\n  232669     1.0     1.0     1.0     1.0     1.0,\n  'pearson_similarity':           131021    64667     6651      706608    232669\n  131021  1.000000  0.071282  0.039617  0.140308  0.080589\n  64667   0.071282  1.000000 -0.053785  0.007398 -0.021716\n  6651    0.039617 -0.053785  1.000000  0.059497  0.036566\n  706608  0.140308  0.007398  0.059497  1.000000 -0.009199\n  232669  0.080589 -0.021716  0.036566 -0.009199  1.000000},\n 39: {'cosine_similarity':             53959       55578       191533      690623      1802849661\n  53959              1.0         1.0         1.0         1.0         1.0\n  55578              1.0         1.0         1.0         1.0         1.0\n  191533             1.0         1.0         1.0         1.0         1.0\n  690623             1.0         1.0         1.0         1.0         1.0\n  1802849661         1.0         1.0         1.0         1.0         1.0,\n  'pearson_similarity':             53959       55578       191533      690623      1802849661\n  53959         1.000000    0.063130   -0.027559    0.051697    0.022169\n  55578         0.063130    1.000000   -0.040875    0.047657   -0.062960\n  191533       -0.027559   -0.040875    1.000000    0.002925   -0.020202\n  690623        0.051697    0.047657    0.002925    1.000000   -0.051269\n  1802849661    0.022169   -0.062960   -0.020202   -0.051269    1.000000}}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation of recommendations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Load the recipes data to map recipe names to their tags\n",
    "recipes = pd.read_csv(\"data/cleaned_recipes_with_country.csv\")\n",
    "COLUMNS = ['time_tags', 'country_tags', 'dietary_tags', 'special_tags', 'ingredients_tags']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Create a mapping from recipe name to its tags\n",
    "recipe_tags_map = {}\n",
    "for index, row in recipes.iterrows():\n",
    "    tags = []\n",
    "    for col in COLUMNS:\n",
    "        tags.extend(row[col].strip('[]').replace(\"'\", \"\").split(', '))\n",
    "    tags = [tag.strip() for tag in tags if tag.strip()]\n",
    "    recipe_tags_map[row['name']] = tags"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "def happiness_score(recommendations, user_profiles):\n",
    "    happiness_scores = []\n",
    "\n",
    "    for group_id, recs in enumerate(recommendations):\n",
    "        group_happiness = []\n",
    "\n",
    "        for user in groups[group_id]:\n",
    "            user_happiness = []\n",
    "            for rec in recs:\n",
    "                tags = recipe_tags_map.get(rec, [])\n",
    "                individual_happiness = np.mean([user_profiles[user].get(tag, 0) for tag in tags])\n",
    "                user_happiness.append(individual_happiness)\n",
    "\n",
    "            group_happiness.append(np.mean(user_happiness))\n",
    "\n",
    "        happiness_scores.append(np.mean(group_happiness))\n",
    "\n",
    "    return happiness_scores\n",
    "\n",
    "def fairness_score(recommendations, user_profiles):\n",
    "    fairness_scores = []\n",
    "\n",
    "    for group_id, recs in enumerate(recommendations):\n",
    "        user_happiness = []\n",
    "\n",
    "        for user in groups[group_id]:\n",
    "            happiness = []\n",
    "            for rec in recs:\n",
    "                tags = recipe_tags_map.get(rec, [])\n",
    "                individual_happiness = np.mean([user_profiles[user].get(tag, 0) for tag in tags])\n",
    "                happiness.append(individual_happiness)\n",
    "\n",
    "            user_happiness.append(np.mean(happiness))\n",
    "\n",
    "        fairness_scores.append(np.std(user_happiness))\n",
    "\n",
    "    return fairness_scores\n",
    "\n",
    "def consensus_score(recommendations, user_profiles):\n",
    "    consensus_scores = []\n",
    "\n",
    "    for group_id, recs in enumerate(recommendations):\n",
    "        group_consensus = []\n",
    "\n",
    "        for rec in recs:\n",
    "            tags = recipe_tags_map.get(rec, [])\n",
    "            tag_ratings = np.array([[user_profiles[user].get(tag, 0) for tag in tags] for user in groups[group_id]])\n",
    "            consensus = np.mean(np.std(tag_ratings, axis=0))\n",
    "            group_consensus.append(consensus)\n",
    "\n",
    "        consensus_scores.append(np.mean(group_consensus))\n",
    "\n",
    "    return consensus_scores\n",
    "\n",
    "def coverage_score(recommendations, user_profiles):\n",
    "    coverage_scores = []\n",
    "\n",
    "    for group_id, recs in enumerate(recommendations):\n",
    "        all_tags = set()\n",
    "        highly_rated_tags = set()\n",
    "\n",
    "        for user in groups[group_id]:\n",
    "            all_tags.update(user_profiles[user].keys())\n",
    "            highly_rated_tags.update([tag for tag, rating in user_profiles[user].items() if rating >= 4])\n",
    "\n",
    "        recommended_tags = set()\n",
    "        for rec in recs:\n",
    "            recommended_tags.update(recipe_tags_map.get(rec, []))\n",
    "\n",
    "        coverage_scores.append(len(recommended_tags.intersection(highly_rated_tags)) / len(all_tags))\n",
    "\n",
    "    return coverage_scores\n",
    "\n",
    "def dcg_score(recommendations, user_profiles):\n",
    "    dcg_scores = []\n",
    "\n",
    "    for group_id, recs in enumerate(recommendations):\n",
    "        group_dcg = []\n",
    "\n",
    "        for user in groups[group_id]:\n",
    "            user_dcg = 0\n",
    "            for i, rec in enumerate(recs):\n",
    "                tags = recipe_tags_map.get(rec, [])\n",
    "                individual_happiness = np.mean([user_profiles[user].get(tag, 0) for tag in tags])\n",
    "                user_dcg += (2**individual_happiness - 1) / np.log2(i + 2)\n",
    "            group_dcg.append(user_dcg)\n",
    "\n",
    "        dcg_scores.append(np.mean(group_dcg))\n",
    "\n",
    "    return dcg_scores\n",
    "\n",
    "def idcg_score(recommendations, user_profiles):\n",
    "    idcg_scores = []\n",
    "\n",
    "    for group_id, recs in enumerate(recommendations):\n",
    "        group_idcg = []\n",
    "\n",
    "        for user in groups[group_id]:\n",
    "            user_idcg = 0\n",
    "            sorted_recs = sorted(recs, key=lambda rec: np.mean([user_profiles[user].get(tag, 0) for tag in recipe_tags_map.get(rec, [])]), reverse=True)\n",
    "            for i, rec in enumerate(sorted_recs):\n",
    "                tags = recipe_tags_map.get(rec, [])\n",
    "                individual_happiness = np.mean([user_profiles[user].get(tag, 0) for tag in tags])\n",
    "                user_idcg += (2**individual_happiness - 1) / np.log2(i + 2)\n",
    "            group_idcg.append(user_idcg)\n",
    "\n",
    "        idcg_scores.append(np.mean(group_idcg))\n",
    "\n",
    "    return idcg_scores\n",
    "\n",
    "def ndcg_score(recommendations, user_profiles):\n",
    "    dcg_scores = dcg_score(recommendations, user_profiles)\n",
    "    idcg_scores = idcg_score(recommendations, user_profiles)\n",
    "    ndcg_scores = [dcg / idcg if idcg != 0 else 0 for dcg, idcg in zip(dcg_scores, idcg_scores)]\n",
    "    return ndcg_scores\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(    Group  Happiness Score  Fairness Score  Consensus Score  Coverage Score  \\\n 0       0         4.090150        0.166098         0.618930        0.086096   \n 1       1         4.151794        0.174198         0.616839        0.088879   \n 2       2         3.539878        0.421654         0.870829        0.098214   \n 3       3         3.807873        0.248005         0.723046        0.077308   \n 4       4         3.941497        0.370582         0.836816        0.089584   \n 5       5         3.883534        0.229595         0.667850        0.091284   \n 6       6         3.950635        0.281256         0.677365        0.102526   \n 7       7         3.673412        0.401567         0.816233        0.083884   \n 8       8         3.905571        0.210426         0.597165        0.084887   \n 9       9         4.171771        0.112775         0.511486        0.095341   \n 10     10         3.785828        0.241332         0.716456        0.093010   \n 11     11         3.870061        0.220917         0.623405        0.104997   \n 12     12         3.388492        0.282703         0.973514        0.084826   \n 13     13         3.910337        0.215721         0.565318        0.070309   \n 14     14         3.972382        0.128114         0.667016        0.083562   \n 15     15         4.004693        0.187067         0.618179        0.101351   \n 16     16         3.789413        0.271577         0.625672        0.096863   \n 17     17         4.064931        0.208368         0.673980        0.081432   \n 18     18         3.883606        0.352195         0.697284        0.095845   \n 19     19         3.915852        0.150440         0.791023        0.079683   \n 20     20         3.848581        0.226914         0.746553        0.077586   \n 21     21         4.020141        0.215292         0.615213        0.097455   \n 22     22         3.905381        0.274015         0.744398        0.095808   \n 23     23         4.013303        0.245917         0.605212        0.084695   \n 24     24         3.818152        0.450808         0.790388        0.076841   \n 25     25         4.171711        0.266642         0.585585        0.075000   \n 26     26         3.813016        0.368858         0.735133        0.093023   \n 27     27         3.859307        0.536829         0.867253        0.089559   \n 28     28         3.864916        0.215760         0.716411        0.101081   \n 29     29         3.912312        0.351662         0.755687        0.087024   \n 30     30         4.060391        0.101305         0.574890        0.087895   \n 31     31         4.168237        0.204055         0.609268        0.090479   \n 32     32         3.450410        0.563288         0.899259        0.084839   \n 33     33         3.899666        0.331940         0.638122        0.087263   \n 34     34         3.780238        0.391165         0.811711        0.079280   \n 35     35         3.952365        0.121661         0.654841        0.103651   \n 36     36         3.840261        0.108366         0.677007        0.078508   \n 37     37         3.907287        0.322586         0.657595        0.090637   \n 38     38         3.803354        0.410709         0.724828        0.064703   \n 39     39         3.943013        0.314745         0.703318        0.077968   \n \n     nDCG Score  \n 0     0.952973  \n 1     0.942912  \n 2     0.878604  \n 3     0.894089  \n 4     0.927389  \n 5     0.882405  \n 6     0.941656  \n 7     0.883101  \n 8     0.930920  \n 9     0.928354  \n 10    0.889277  \n 11    0.925096  \n 12    0.885243  \n 13    0.940348  \n 14    0.905043  \n 15    0.946697  \n 16    0.924555  \n 17    0.930350  \n 18    0.935692  \n 19    0.906283  \n 20    0.935751  \n 21    0.939284  \n 22    0.899349  \n 23    0.914384  \n 24    0.899453  \n 25    0.939618  \n 26    0.957032  \n 27    0.957618  \n 28    0.949230  \n 29    0.943882  \n 30    0.929068  \n 31    0.914293  \n 32    0.957468  \n 33    0.845959  \n 34    0.915359  \n 35    0.933142  \n 36    0.915976  \n 37    0.958941  \n 38    0.920140  \n 39    0.912530  ,\n     Group  Happiness Score  Fairness Score  Consensus Score  Coverage Score  \\\n 0       0         4.090150        0.166098         0.618930        0.086096   \n 1       1         4.151794        0.174198         0.616839        0.088879   \n 2       2         3.539878        0.421654         0.870829        0.098214   \n 3       3         3.807873        0.248005         0.723046        0.077308   \n 4       4         3.941497        0.370582         0.836816        0.089584   \n 5       5         3.883534        0.229595         0.667850        0.091284   \n 6       6         3.950635        0.281256         0.677365        0.102526   \n 7       7         3.673412        0.401567         0.816233        0.083884   \n 8       8         3.905571        0.210426         0.597165        0.084887   \n 9       9         4.171771        0.112775         0.511486        0.095341   \n 10     10         3.785828        0.241332         0.716456        0.093010   \n 11     11         3.870061        0.220917         0.623405        0.104997   \n 12     12         3.388492        0.282703         0.973514        0.084826   \n 13     13         3.910337        0.215721         0.565318        0.070309   \n 14     14         3.972382        0.128114         0.667016        0.083562   \n 15     15         4.004693        0.187067         0.618179        0.101351   \n 16     16         3.789413        0.271577         0.625672        0.096863   \n 17     17         4.064931        0.208368         0.673980        0.081432   \n 18     18         3.883606        0.352195         0.697284        0.095845   \n 19     19         3.915852        0.150440         0.791023        0.079683   \n 20     20         3.848581        0.226914         0.746553        0.077586   \n 21     21         4.020141        0.215292         0.615213        0.097455   \n 22     22         3.905381        0.274015         0.744398        0.095808   \n 23     23         4.013303        0.245917         0.605212        0.084695   \n 24     24         3.818152        0.450808         0.790388        0.076841   \n 25     25         4.171711        0.266642         0.585585        0.075000   \n 26     26         3.813016        0.368858         0.735133        0.093023   \n 27     27         3.859307        0.536829         0.867253        0.089559   \n 28     28         3.864916        0.215760         0.716411        0.101081   \n 29     29         3.912312        0.351662         0.755687        0.087024   \n 30     30         4.060391        0.101305         0.574890        0.087895   \n 31     31         4.168237        0.204055         0.609268        0.090479   \n 32     32         3.450410        0.563288         0.899259        0.084839   \n 33     33         3.899666        0.331940         0.638122        0.087263   \n 34     34         3.780238        0.391165         0.811711        0.079280   \n 35     35         3.952365        0.121661         0.654841        0.103651   \n 36     36         3.840261        0.108366         0.677007        0.078508   \n 37     37         3.907287        0.322586         0.657595        0.090637   \n 38     38         3.803354        0.410709         0.724828        0.064703   \n 39     39         3.943013        0.314745         0.703318        0.077968   \n \n     nDCG Score  \n 0     0.952973  \n 1     0.942912  \n 2     0.878604  \n 3     0.894089  \n 4     0.927389  \n 5     0.882405  \n 6     0.941656  \n 7     0.883101  \n 8     0.930920  \n 9     0.928354  \n 10    0.889277  \n 11    0.925096  \n 12    0.885243  \n 13    0.940348  \n 14    0.905043  \n 15    0.946697  \n 16    0.924555  \n 17    0.930350  \n 18    0.935692  \n 19    0.906283  \n 20    0.935751  \n 21    0.939284  \n 22    0.899349  \n 23    0.914384  \n 24    0.899453  \n 25    0.939618  \n 26    0.957032  \n 27    0.957618  \n 28    0.949230  \n 29    0.943882  \n 30    0.929068  \n 31    0.914293  \n 32    0.957468  \n 33    0.845959  \n 34    0.915359  \n 35    0.933142  \n 36    0.915976  \n 37    0.958941  \n 38    0.920140  \n 39    0.912530  ,\n     Group  Happiness Score  Fairness Score  Consensus Score  Coverage Score  \\\n 0       0         4.165437        0.141139         0.530225        0.108362   \n 1       1         4.268610        0.110656         0.515037        0.095859   \n 2       2         4.017690        0.353953         0.672533        0.109933   \n 3       3         4.218617        0.127006         0.518696        0.100045   \n 4       4         4.099028        0.317506         0.624758        0.106314   \n 5       5         4.105668        0.160082         0.514961        0.109335   \n 6       6         4.187440        0.172346         0.575472        0.102526   \n 7       7         3.747426        0.334121         0.730116        0.110320   \n 8       8         4.147438        0.097984         0.445525        0.102552   \n 9       9         4.199833        0.054345         0.495182        0.108342   \n 10     10         3.976394        0.342709         0.651465        0.131535   \n 11     11         4.234785        0.110267         0.524719        0.133460   \n 12     12         4.097461        0.424555         0.720653        0.107482   \n 13     13         4.142395        0.067172         0.532004        0.099287   \n 14     14         3.926722        0.127412         0.644236        0.115448   \n 15     15         4.274524        0.141978         0.543726        0.107588   \n 16     16         4.075247        0.162818         0.535258        0.115025   \n 17     17         4.089124        0.236961         0.597622        0.102013   \n 18     18         4.057718        0.317639         0.634448        0.113573   \n 19     19         4.041990        0.293687         0.619309        0.088127   \n 20     20         4.034032        0.168328         0.625853        0.100406   \n 21     21         4.368848        0.147128         0.521134        0.093665   \n 22     22         4.018747        0.324140         0.758998        0.105607   \n 23     23         4.180365        0.118813         0.489168        0.100545   \n 24     24         3.898076        0.287509         0.733861        0.118463   \n 25     25         4.364736        0.159054         0.489273        0.109239   \n 26     26         3.924408        0.310290         0.654678        0.117413   \n 27     27         3.952246        0.498885         0.838336        0.104406   \n 28     28         4.062119        0.170114         0.549336        0.118378   \n 29     29         4.111525        0.123125         0.545547        0.117249   \n 30     30         4.126057        0.177000         0.583520        0.113158   \n 31     31         4.365734        0.188748         0.409403        0.083114   \n 32     32         3.853557        0.471393         0.770061        0.107932   \n 33     33         4.240114        0.205860         0.553596        0.102688   \n 34     34         4.067739        0.265470         0.585453        0.107490   \n 35     35         4.266421        0.190898         0.488230        0.092462   \n 36     36         4.172862        0.408541         0.702416        0.109131   \n 37     37         4.035182        0.256161         0.586668        0.109562   \n 38     38         3.961776        0.352743         0.649455        0.096791   \n 39     39         4.037881        0.181653         0.516444        0.099095   \n \n     nDCG Score  \n 0     0.942191  \n 1     0.945654  \n 2     0.928788  \n 3     0.947136  \n 4     0.954631  \n 5     0.951903  \n 6     0.958932  \n 7     0.930971  \n 8     0.957701  \n 9     0.934999  \n 10    0.950930  \n 11    0.963734  \n 12    0.956247  \n 13    0.952719  \n 14    0.914711  \n 15    0.933256  \n 16    0.939767  \n 17    0.950935  \n 18    0.948692  \n 19    0.910707  \n 20    0.927290  \n 21    0.954494  \n 22    0.960792  \n 23    0.945600  \n 24    0.925937  \n 25    0.903456  \n 26    0.875263  \n 27    0.952066  \n 28    0.949706  \n 29    0.930097  \n 30    0.965247  \n 31    0.941021  \n 32    0.917198  \n 33    0.931165  \n 34    0.936344  \n 35    0.971625  \n 36    0.935560  \n 37    0.972058  \n 38    0.947172  \n 39    0.943362  )"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get groups and compute metrics\n",
    "groups = get_groups(groups_exp_1)\n",
    "\n",
    "# Separate the recommendations for different aggregation methods\n",
    "average_recommendations = recommendations_exp_1[0]\n",
    "least_misery_recommendations = recommendations_exp_1[1]\n",
    "most_pleasure_recommendations = recommendations_exp_1[2]\n",
    "\n",
    "# Calculating the metrics for each method\n",
    "happiness_scores_avg = happiness_score(average_recommendations, user_profiles)\n",
    "fairness_scores_avg = fairness_score(average_recommendations, user_profiles)\n",
    "consensus_scores_avg = consensus_score(average_recommendations, user_profiles)\n",
    "coverage_scores_avg = coverage_score(average_recommendations, user_profiles)\n",
    "ndcg_scores_avg = ndcg_score(average_recommendations, user_profiles)\n",
    "\n",
    "happiness_scores_lm = happiness_score(least_misery_recommendations, user_profiles)\n",
    "fairness_scores_lm = fairness_score(least_misery_recommendations, user_profiles)\n",
    "consensus_scores_lm = consensus_score(least_misery_recommendations, user_profiles)\n",
    "coverage_scores_lm = coverage_score(least_misery_recommendations, user_profiles)\n",
    "ndcg_scores_lm = ndcg_score(least_misery_recommendations, user_profiles)\n",
    "\n",
    "happiness_scores_mp = happiness_score(most_pleasure_recommendations, user_profiles)\n",
    "fairness_scores_mp = fairness_score(most_pleasure_recommendations, user_profiles)\n",
    "consensus_scores_mp = consensus_score(most_pleasure_recommendations, user_profiles)\n",
    "coverage_scores_mp = coverage_score(most_pleasure_recommendations, user_profiles)\n",
    "ndcg_scores_mp = ndcg_score(most_pleasure_recommendations, user_profiles)\n",
    "\n",
    "# Display the results for each method\n",
    "metrics_avg = pd.DataFrame({\n",
    "    'Group': list(groups.keys()),\n",
    "    'Happiness Score': happiness_scores_avg,\n",
    "    'Fairness Score': fairness_scores_avg,\n",
    "    'Consensus Score': consensus_scores_avg,\n",
    "    'Coverage Score': coverage_scores_avg,\n",
    "    'nDCG Score': ndcg_scores_avg\n",
    "})\n",
    "\n",
    "metrics_lm = pd.DataFrame({\n",
    "    'Group': list(groups.keys()),\n",
    "    'Happiness Score': happiness_scores_lm,\n",
    "    'Fairness Score': fairness_scores_lm,\n",
    "    'Consensus Score': consensus_scores_lm,\n",
    "    'Coverage Score': coverage_scores_lm,\n",
    "    'nDCG Score': ndcg_scores_lm\n",
    "})\n",
    "\n",
    "metrics_mp = pd.DataFrame({\n",
    "    'Group': list(groups.keys()),\n",
    "    'Happiness Score': happiness_scores_mp,\n",
    "    'Fairness Score': fairness_scores_mp,\n",
    "    'Consensus Score': consensus_scores_mp,\n",
    "    'Coverage Score': coverage_scores_mp,\n",
    "    'nDCG Score': ndcg_scores_mp\n",
    "})\n",
    "\n",
    "metrics_avg, metrics_lm, metrics_mp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics for Average Aggregation Strategy\n",
      "Group              19.500000\n",
      "Happiness Score     3.893344\n",
      "Fairness Score      0.272428\n",
      "Consensus Score     0.700027\n",
      "Coverage Score      0.087830\n",
      "nDCG Score          0.922237\n",
      "dtype: float64\n",
      "\n",
      "Average Metrics for Least Misery Aggregation Strategy\n",
      "Group              19.500000\n",
      "Happiness Score     3.893344\n",
      "Fairness Score      0.272428\n",
      "Consensus Score     0.700027\n",
      "Coverage Score      0.087830\n",
      "nDCG Score          0.922237\n",
      "dtype: float64\n",
      "\n",
      "Average Metrics for Most Pleasure Aggregation Strategy\n",
      "Group              19.500000\n",
      "Happiness Score     4.102899\n",
      "Fairness Score      0.227505\n",
      "Consensus Score     0.591934\n",
      "Coverage Score      0.106848\n",
      "nDCG Score          0.941501\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the average for all groups\n",
    "avg_metrics_avg = metrics_avg.mean()\n",
    "avg_metrics_lm = metrics_lm.mean()\n",
    "avg_metrics_mp = metrics_mp.mean()\n",
    "\n",
    "print(\"Average Metrics for Average Aggregation Strategy\")\n",
    "print(avg_metrics_avg)\n",
    "\n",
    "print(\"\\nAverage Metrics for Least Misery Aggregation Strategy\")\n",
    "print(avg_metrics_lm)\n",
    "\n",
    "print(\"\\nAverage Metrics for Most Pleasure Aggregation Strategy\")\n",
    "print(avg_metrics_mp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Explore why average and least misery have the same values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample recommendations for Average Aggregation Strategy:\n",
      "['copycat p f  chang s singapore street noodles', 'pappadeaux snapper ponchartrain', 'skips chili seasoning mix', 'gourmet bangers   mash', 'oven  fried  fish', 'pub style fish and chips', 'szechuan style eggplants', 'beef and scallops', 'beer battered fish with tartar sauce', 'fish fillet with garlic butter and black olives']\n",
      "['delicious grilled chicken marinade', 'mesa burgers with sage aioli and spicy chips', 'cherry sauce for grilled salmon', 'grandma s grape jelly', 'kicked up fish cakes', 'pina banana colada', 'party punch ice ring', 'cape malay mango atjar   south african mango chutney', 'chicken ala mayo', 'maple roasted turkey  smoky sage cornbread stuffing   gravy']\n",
      "\n",
      "Sample recommendations for Least Misery Aggregation Strategy:\n",
      "['copycat p f  chang s singapore street noodles', 'pappadeaux snapper ponchartrain', 'skips chili seasoning mix', 'gourmet bangers   mash', 'oven  fried  fish', 'pub style fish and chips', 'szechuan style eggplants', 'beef and scallops', 'beer battered fish with tartar sauce', 'fish fillet with garlic butter and black olives']\n",
      "['delicious grilled chicken marinade', 'mesa burgers with sage aioli and spicy chips', 'cherry sauce for grilled salmon', 'grandma s grape jelly', 'kicked up fish cakes', 'pina banana colada', 'party punch ice ring', 'cape malay mango atjar   south african mango chutney', 'chicken ala mayo', 'maple roasted turkey  smoky sage cornbread stuffing   gravy']\n",
      "\n",
      "Sample recommendations for Most Pleasure Aggregation Strategy:\n",
      "['my breakfast frittata', 'sheer korma', 'cheese ball 2', 'taco salad supreme', 'sausage with warm fruit', 'worth staying home for steak', 'coconut chocolate tarts', 'grandma b s southern cajun meatloaf', 'sea scallop saute', 'leftover roast beef spicy salad']\n",
      "['cheese ball 2', 'my breakfast frittata', 'taco salad supreme', 'cheese ball 1', 'dried beef cheese ball 3', 'ceviche with ahi tuna', 'chipotle chicken taco salad', 'a refreshing salad to usher in summer', 'spicy broiled chicken', 'smothered oxtails over spinach and sweet corn mash']\n"
     ]
    }
   ],
   "source": [
    "# Sample debug prints to compare recommendations\n",
    "print(\"Sample recommendations for Average Aggregation Strategy:\")\n",
    "for group_recs in average_recommendations[:2]:  # Printing first 2 groups for brevity\n",
    "    print(group_recs)\n",
    "\n",
    "print(\"\\nSample recommendations for Least Misery Aggregation Strategy:\")\n",
    "for group_recs in least_misery_recommendations[:2]:  # Printing first 2 groups for brevity\n",
    "    print(group_recs)\n",
    "\n",
    "print(\"\\nSample recommendations for Most Pleasure Aggregation Strategy:\")\n",
    "for group_recs in most_pleasure_recommendations[:2]:  # Printing first 2 groups for brevity\n",
    "    print(group_recs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The average and least misery strategy recommend the same recipes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
